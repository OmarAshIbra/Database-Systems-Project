{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM5l+WI4kTZkUDqdDZeFWqt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OmarAshIbra/Database-Systems-Project/blob/main/The_Final_Stage_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwDyvSg2PzXn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "import numpy as np\n",
        "import random\n",
        "import torchvision.models as models\n",
        "from collections import deque\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize global variables\n",
        "# drone_speed = 0.21\n",
        "# bus_speed = 0.75\n",
        "# global_time = 0\n",
        "# num_points = 4 # Example number of points\n",
        "# # Define the number of trips between each station\n",
        "# num_trips = num_points *3\n",
        "\n",
        "# # Define the time duration for each trip (in seconds)\n",
        "# trip_duration = 100"
      ],
      "metadata": {
        "id": "5wmSj-8jQ8IT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Class to genrate the DATA"
      ],
      "metadata": {
        "id": "begbfOPYP7yz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class to genrate all data:\n",
        "class TransportationScheduler:\n",
        "    def __init__(self, num_points, drone_speed, bus_speed,trip_duration,seed=None):\n",
        "        self.num_points = num_points\n",
        "        self.trip_duration = trip_duration\n",
        "        self.num_trips = num_points\n",
        "        self.drone_speed = drone_speed\n",
        "        self.bus_speed = bus_speed\n",
        "         # Set the seed for reproducibility\n",
        "        if seed is not None:\n",
        "            np.random.seed(seed)\n",
        "            torch.manual_seed(seed)\n",
        "        self.coordinates = torch.rand(num_points, 4)  # Random coordinates\n",
        "        self.bus_coordinates = torch.tensor([[0.15, 0.85], [0.5, 0.5], [0.85, 0.15]])\n",
        "        self.bus_schedules = self.generate_bus_schedules()\n",
        "\n",
        "    def euclidean_distance(self, point1, point2):\n",
        "        return ((point1[0] - point2[0])**2 + (point1[1] - point2[1])**2).sqrt()\n",
        "\n",
        "    def get_bus_coordinates(self):\n",
        "        return self.bus_coordinates\n",
        "    def get_bus_schedules(self):\n",
        "        return self.bus_schedules\n",
        "\n",
        "    def generate_bus_schedules(self):\n",
        "        bus_schedules = []\n",
        "        for bus_id, start_station in enumerate(self.bus_coordinates, 1):\n",
        "            departures = np.arange(0, self.num_trips * self.trip_duration, 20)  # Departure times with 20 seconds interval\n",
        "            destinations = []\n",
        "\n",
        "            # Ensure that each destination is different from the start station\n",
        "            for _ in range(self.num_trips):\n",
        "                dest = torch.randint(1, len(self.bus_coordinates) + 1, (1,)).item()\n",
        "                while dest == bus_id:  # Avoid trips to the same station\n",
        "                    dest = torch.randint(1, len(self.bus_coordinates) + 1, (1,)).item()\n",
        "                destinations.append(dest)\n",
        "\n",
        "            arrival_times = []\n",
        "            for i, dest in enumerate(destinations):\n",
        "                dest_station = self.bus_coordinates[dest - 1]  # Coordinates of the destination station\n",
        "                distance = self.euclidean_distance(start_station, dest_station)\n",
        "                travel_time = distance / self.bus_speed  # Assuming constant speed\n",
        "                arrival_times.append(departures[i] + travel_time.item())  # Arrival time = Departure time + Travel time\n",
        "\n",
        "            # Combine departure times, destinations, and arrival times for the current bus\n",
        "            bus_schedule = list(zip(departures.tolist(), destinations, arrival_times))\n",
        "            bus_schedules.append(bus_schedule)\n",
        "        return bus_schedules\n",
        "\n",
        "\n",
        "\n",
        "    def closest_bus_station(self, point):\n",
        "        min_distance = float('inf')\n",
        "        closest_station = None\n",
        "        for i, station in enumerate(self.bus_coordinates):\n",
        "            distance = self.euclidean_distance(point, station)\n",
        "            if distance < min_distance:\n",
        "                min_distance = distance\n",
        "                closest_station = i + 1\n",
        "        return closest_station\n",
        "\n",
        "    def calculate_distance(self, point1, point2):\n",
        "        closest_station_point1 = self.closest_bus_station(point1)\n",
        "        closest_station_point2 = self.closest_bus_station(point2)\n",
        "\n",
        "        distance_point1_to_station = self.euclidean_distance(point1, self.bus_coordinates[closest_station_point1 - 1])\n",
        "        distance_stations = self.euclidean_distance(self.bus_coordinates[closest_station_point1 - 1], self.bus_coordinates[closest_station_point2 - 1])\n",
        "        distance_station_to_point2 = self.euclidean_distance(self.bus_coordinates[closest_station_point2 - 1], point2)\n",
        "\n",
        "        total_distance = distance_point1_to_station + distance_stations + distance_station_to_point2\n",
        "        return total_distance\n",
        "\n",
        "    def calculate_optimal_order(self, root_point):\n",
        "        distances_to_root = [(i, self.calculate_distance(root_point, point)) for i, point in enumerate(self.coordinates)]\n",
        "        optimal_order = sorted(distances_to_root, key=lambda x: x[1])\n",
        "        optimal_indices = [point[0] for point in optimal_order]\n",
        "        self.coordinates = self.coordinates[optimal_indices]\n",
        "        return self.coordinates\n",
        "\n",
        "    def find_next_trip(self, global_time, bus_schedule, start_station, end_station):\n",
        "        for departure, destination, arrival in bus_schedule[start_station - 1]:\n",
        "            if destination == end_station and departure >= global_time:\n",
        "                waiting_time = departure - global_time\n",
        "                travel_time = arrival - departure\n",
        "                return waiting_time, travel_time\n",
        "        return float('inf'), float('inf')  # If no valid trip is found\n",
        "\n",
        "    def calculate_times(self, root_point):\n",
        "        global_time = 0\n",
        "        root_index = 0  # Assuming root_point is always the first point\n",
        "\n",
        "        # Set the root point's ti and tf to zero\n",
        "        self.coordinates[root_index, 2] = 0\n",
        "        self.coordinates[root_index, 3] = 0\n",
        "\n",
        "        # Iterate through each point (excluding the root point)\n",
        "        for i, point in enumerate(self.coordinates[1:], start=1):\n",
        "            local_time = 0\n",
        "            distance = self.euclidean_distance(root_point, point)\n",
        "\n",
        "            # Closest bus stations\n",
        "            closest_station_root = self.closest_bus_station(root_point)\n",
        "            closest_station_point = self.closest_bus_station(point)\n",
        "\n",
        "            if closest_station_root == closest_station_point:\n",
        "                # If both points share the same closest bus station, go directly to the point\n",
        "                travel_time = (distance / self.drone_speed)*2\n",
        "                local_time += travel_time +5\n",
        "                global_time += local_time\n",
        "\n",
        "            else:\n",
        "                # From root to closest bus station\n",
        "                distance_root_to_station = self.euclidean_distance(root_point, self.bus_coordinates[closest_station_root - 1])\n",
        "                time_root_to_station = distance_root_to_station / self.drone_speed\n",
        "                local_time += time_root_to_station+5\n",
        "                global_time += local_time\n",
        "\n",
        "                # Find the next trip\n",
        "                bus_schedule = self.bus_schedules[closest_station_root - 1]\n",
        "                next_trip = next((trip for trip in bus_schedule if trip[1] == closest_station_point and trip[0] >= global_time), None)\n",
        "\n",
        "                if next_trip:\n",
        "                    waiting_time = next_trip[0] - global_time\n",
        "                    travel_time = next_trip[2] - next_trip[0]\n",
        "                    local_time += waiting_time + travel_time+5\n",
        "                    global_time += local_time\n",
        "\n",
        "                # From closest bus station to delivery point\n",
        "                distance_station_to_point = self.euclidean_distance(self.bus_coordinates[closest_station_point - 1], point)\n",
        "                time_station_to_point = distance_station_to_point / self.drone_speed\n",
        "                local_time += time_station_to_point+5\n",
        "                global_time += local_time\n",
        "\n",
        "            # Update ti and tf\n",
        "            self.coordinates[i, 2] = max(global_time - local_time, 0)\n",
        "            self.coordinates[i, 3] = global_time + (distance / self.drone_speed)\n",
        "\n",
        "        # Sort points by ti (excluding the root point)\n",
        "        self.coordinates[1:] = self.coordinates[1:][self.coordinates[1:, 2].argsort()]\n",
        "\n",
        "        return self.coordinates\n",
        "\n",
        "\n",
        "    def get_optimal_order(self):\n",
        "\n",
        "\n",
        "        return self.coordinates\n",
        "\n",
        "    def get_shuffled_coordinates(self):\n",
        "        root_point = self.coordinates[0]\n",
        "        remaining_points = self.coordinates[1:]  # Exclude the root point\n",
        "        shuffled_indices = np.random.permutation(len(remaining_points))\n",
        "        shuffled_remaining_points = remaining_points[shuffled_indices]\n",
        "\n",
        "        # Combine the root point with the shuffled remaining points\n",
        "        shuffled_coordinates = torch.cat((root_point.unsqueeze(0), shuffled_remaining_points), dim=0)\n",
        "        return shuffled_coordinates\n"
      ],
      "metadata": {
        "id": "wdDWE2c5QBzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test The Class"
      ],
      "metadata": {
        "id": "r_eYnWg4Oa4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage of the Class:\n",
        "scheduler = TransportationScheduler(5,0.045,1.25,100)\n",
        "root_point = scheduler.coordinates[0]\n",
        "optimal_coordinates = scheduler.calculate_optimal_order(root_point)\n",
        "updated_coordinates = scheduler.calculate_times(root_point)\n",
        "poits= scheduler.get_optimal_order()\n",
        "shuffled_coordinates = scheduler.get_shuffled_coordinates()\n",
        "\n",
        "\n",
        "print(\"Updated Coordinates with Time Bounds:\")\n",
        "print(updated_coordinates)\n",
        "print(\"Updated Coordinates with Time Bounds using get_optimal_order :\")\n",
        "print(updated_coordinates)\n",
        "print(\"Shuffled Coordinates:\")\n",
        "print(shuffled_coordinates)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4q1m-3hrQWKV",
        "outputId": "1bddac3e-1142-4e69-b8fa-6d67d11dcec2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated Coordinates with Time Bounds:\n",
            "tensor([[ 0.4976,  0.4140,  0.0000,  0.0000],\n",
            "        [ 0.3619,  0.3616,  0.0000, 14.6990],\n",
            "        [ 0.3812,  0.2149, 11.4660, 31.8444],\n",
            "        [ 0.8569,  0.8362, 26.7183, 68.6775],\n",
            "        [ 0.6347,  0.2038, 63.2695, 85.6904]])\n",
            "Updated Coordinates with Time Bounds using get_optimal_order :\n",
            "tensor([[ 0.4976,  0.4140,  0.0000,  0.0000],\n",
            "        [ 0.3619,  0.3616,  0.0000, 14.6990],\n",
            "        [ 0.3812,  0.2149, 11.4660, 31.8444],\n",
            "        [ 0.8569,  0.8362, 26.7183, 68.6775],\n",
            "        [ 0.6347,  0.2038, 63.2695, 85.6904]])\n",
            "Shuffled Coordinates:\n",
            "tensor([[ 0.4976,  0.4140,  0.0000,  0.0000],\n",
            "        [ 0.6347,  0.2038, 63.2695, 85.6904],\n",
            "        [ 0.3812,  0.2149, 11.4660, 31.8444],\n",
            "        [ 0.8569,  0.8362, 26.7183, 68.6775],\n",
            "        [ 0.3619,  0.3616,  0.0000, 14.6990]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing The Process\n"
      ],
      "metadata": {
        "id": "aa89xMVoOjZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Plot Points, Root, and Bus Stations with Optimal Order and Rank\n",
        "def plot_points_and_order(scheduler):\n",
        "    optimal_coordinates = scheduler.calculate_optimal_order(scheduler.coordinates[0])\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.scatter(optimal_coordinates[:, 0], optimal_coordinates[:, 1], c='green', s=100, marker='o')\n",
        "\n",
        "    # Plot the order with distinguishable labels\n",
        "    for idx, point in enumerate(optimal_coordinates):\n",
        "        plt.text(point[0], point[1], f'{idx}', fontsize=12, ha='right' if idx == 0 else 'left', color='red' if idx == 0 else 'blue')\n",
        "\n",
        "    plt.plot(optimal_coordinates[:, 0], optimal_coordinates[:, 1], c='orange', linestyle='--', label='Optimal Order')\n",
        "\n",
        "    plt.title('Optimal Order of Points with Ranks')\n",
        "    plt.xlabel('X Coordinate')\n",
        "    plt.ylabel('Y Coordinate')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# 2. Plot Route for Each Point Individually and Combined\n",
        "def plot_routes_individual(scheduler, point_idx):\n",
        "    root_point = scheduler.coordinates[0, :2]\n",
        "    point = scheduler.coordinates[point_idx, :2]\n",
        "    bus_coordinates = scheduler.bus_coordinates\n",
        "\n",
        "    # Function to plot the path between points\n",
        "    def plot_path(start, end, color='k', linestyle='-', label=None):\n",
        "        plt.plot([start[0], end[0]], [start[1], end[1]], color=color, linestyle=linestyle, label=label)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    # Plot the bus stations\n",
        "    for i, bus_station in enumerate(bus_coordinates):\n",
        "        plt.plot(bus_station[0], bus_station[1], 'gs')  # Plot bus stations in green squares\n",
        "        plt.annotate(f'Bus {i+1}', (bus_station[0], bus_station[1]), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
        "\n",
        "    # Plot the root point\n",
        "    plt.plot(root_point[0], root_point[1], 'bo', label='Root')  # Plot root point in blue\n",
        "    plt.annotate('Root', (root_point[0], root_point[1]), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
        "\n",
        "    # Plot the point and its route\n",
        "    closest_station_root = bus_coordinates[scheduler.closest_bus_station(root_point) - 1]\n",
        "    closest_station_point = bus_coordinates[scheduler.closest_bus_station(point) - 1]\n",
        "\n",
        "    plt.plot(point[0], point[1], 'ro')  # Plot delivery point in red\n",
        "    plt.annotate(f'{point_idx}', (point[0], point[1]), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
        "\n",
        "    # Plot the path from root to its closest bus station\n",
        "    plot_path(root_point, closest_station_root, color='b', linestyle='--')\n",
        "\n",
        "    # Plot the path from the closest bus station to the closest bus station to the point\n",
        "    plot_path(closest_station_root, closest_station_point, color='g', linestyle='--')\n",
        "\n",
        "    # Plot the path from the closest bus station to the point\n",
        "    plot_path(closest_station_point, point, color='r', linestyle='--')\n",
        "\n",
        "    plt.title(f\"Route from Root to Point {point_idx}\")\n",
        "    plt.xlabel(\"X-coordinate\")\n",
        "    plt.ylabel(\"Y-coordinate\")\n",
        "    plt.xlim(0, 1)\n",
        "    plt.ylim(0, 1)\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def plot_routes_combined(scheduler):\n",
        "    root_point = scheduler.coordinates[0, :2]\n",
        "    coordinates = scheduler.coordinates[:, :2]\n",
        "    bus_coordinates = scheduler.bus_coordinates\n",
        "    optimal_order_indices = range(len(scheduler.coordinates))\n",
        "\n",
        "    # Function to plot the path between points\n",
        "    def plot_path(start, end, color='k', linestyle='-', label=None):\n",
        "        plt.plot([start[0], end[0]], [start[1], end[1]], color=color, linestyle=linestyle, label=label)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    # Plot the bus stations\n",
        "    for i, bus_station in enumerate(bus_coordinates):\n",
        "        plt.plot(bus_station[0], bus_station[1], 'gs')  # Plot bus stations in green squares\n",
        "        plt.annotate(f'Bus {i+1}', (bus_station[0], bus_station[1]), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
        "\n",
        "    # Plot the root point\n",
        "    plt.plot(root_point[0], root_point[1], 'bo', label='Root')  # Plot root point in blue\n",
        "    plt.annotate('Root', (root_point[0], root_point[1]), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
        "\n",
        "    # Plot the points and their routes\n",
        "    for idx in optimal_order_indices:\n",
        "        point = coordinates[idx]\n",
        "        closest_station_root = bus_coordinates[scheduler.closest_bus_station(root_point) - 1]\n",
        "        closest_station_point = bus_coordinates[scheduler.closest_bus_station(point) - 1]\n",
        "\n",
        "        plt.plot(point[0], point[1], 'ro')  # Plot delivery point in red\n",
        "        plt.annotate(f'{idx}', (point[0], point[1]), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
        "\n",
        "        # Plot the path from root to its closest bus station\n",
        "        plot_path(root_point, closest_station_root, color='b', linestyle='--')\n",
        "\n",
        "        # Plot the path from the closest bus station to the closest bus station to the point\n",
        "        plot_path(closest_station_root, closest_station_point, color='g', linestyle='--')\n",
        "\n",
        "        # Plot the path from the closest bus station to the point\n",
        "        plot_path(closest_station_point, point, color='r', linestyle='--')\n",
        "\n",
        "    plt.title(\"Optimal Delivery Route with Bus Stations\")\n",
        "    plt.xlabel(\"X-coordinate\")\n",
        "    plt.ylabel(\"Y-coordinate\")\n",
        "    plt.xlim(0, 1)\n",
        "    plt.ylim(0, 1)\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# 3. Modify the Time Windows (ti, tf) Plot\n",
        "def plot_time_windows(scheduler):\n",
        "    coordinates = scheduler.get_optimal_order()\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    ti = coordinates[:, 2].numpy()\n",
        "    tf = coordinates[:, 3].numpy()\n",
        "    indices = np.arange(len(ti))\n",
        "\n",
        "    plt.plot(indices, ti, 'ro-', label='ti (start time)')\n",
        "    plt.plot(indices, tf, 'go-', label='tf (end time)')\n",
        "\n",
        "    plt.xticks(indices, [f'Point {i}' for i in indices])\n",
        "    plt.xlabel('Points')\n",
        "    plt.ylabel('Time')\n",
        "    plt.title('Time Windows for Each Point')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# 4. Modify the Drone and Bus Distance Plot\n",
        "def plot_drone_and_bus_distance(scheduler):\n",
        "    drone_distances = []\n",
        "    bus_distances = []\n",
        "\n",
        "    for point in scheduler.coordinates[1:]:\n",
        "        closest_station_root = scheduler.closest_bus_station(scheduler.coordinates[0])\n",
        "        closest_station_point = scheduler.closest_bus_station(point)\n",
        "\n",
        "        if closest_station_root == closest_station_point:\n",
        "            # Direct distance by drone\n",
        "            drone_distance = scheduler.euclidean_distance(scheduler.coordinates[0], point).item()\n",
        "            bus_distance = 0\n",
        "        else:\n",
        "            # Distance by drone to station\n",
        "            drone_distance = scheduler.euclidean_distance(scheduler.coordinates[0], scheduler.bus_coordinates[closest_station_root - 1]).item()\n",
        "            # Distance by bus between stations\n",
        "            bus_distance = scheduler.euclidean_distance(scheduler.bus_coordinates[closest_station_root - 1], scheduler.bus_coordinates[closest_station_point - 1]).item()\n",
        "            # Distance by drone from station to point\n",
        "            drone_distance += scheduler.euclidean_distance(scheduler.bus_coordinates[closest_station_point - 1], point).item()\n",
        "\n",
        "        drone_distances.append(drone_distance)\n",
        "        bus_distances.append(bus_distance)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    indices = np.arange(len(drone_distances))\n",
        "\n",
        "    plt.plot(indices, drone_distances, 'bo-', label='Drone Distance')\n",
        "    plt.plot(indices, bus_distances, 'go-', label='Bus Distance')\n",
        "\n",
        "    plt.xticks(indices, [f'Point {i+1}' for i in indices])\n",
        "    plt.xlabel('Points')\n",
        "    plt.ylabel('Distance')\n",
        "    plt.title('Distance Traveled by Drone and Bus for Each Point')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# 5. Pie Chart Showing Time Contribution of Each Point\n",
        "def plot_time_contribution_pie(scheduler):\n",
        "    coordinates = scheduler.get_optimal_order()\n",
        "    tf = coordinates[:, 3].numpy()\n",
        "\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.pie(tf, labels=[f'Point {i}' for i in range(len(tf))], autopct='%1.1f%%', startangle=140)\n",
        "    plt.title('Time Contribution of Each Point')\n",
        "    plt.show()\n",
        "\n",
        "# 6. Plot Points, Root, and Bus Stations\n",
        "def plot_points_and_stations(scheduler):\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    # Plot bus stations\n",
        "    bus_coordinates = scheduler.get_bus_coordinates()\n",
        "    plt.scatter(bus_coordinates[:, 0], bus_coordinates[:, 1], c='blue', s=100, marker='s', label='Bus Stations')\n",
        "\n",
        "    # Plot root point\n",
        "    plt.scatter(scheduler.coordinates[0, 0], scheduler.coordinates[0, 1], c='red', s=100, marker='*', label='Root Point')\n",
        "\n",
        "    # Plot other points\n",
        "    plt.scatter(scheduler.coordinates[1:, 0], scheduler.coordinates[1:, 1], c='green', s=100, marker='o', label='Points')\n",
        "\n",
        "    plt.title('Points, Root, and Bus Stations')\n",
        "    plt.xlabel('X Coordinate')\n",
        "    plt.ylabel('Y Coordinate')\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "_ANMhW3TOvaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Problem space\n",
        "We will plot the points (delivery points), root (starting point), and bus stations with different shapes and colors to distinguish them."
      ],
      "metadata": {
        "id": "Y-fS1Wm_RjT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calling the functions to plot the data\n",
        "plot_points_and_stations(scheduler)\n"
      ],
      "metadata": {
        "id": "74qkF8LzRCjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The bus schedules"
      ],
      "metadata": {
        "id": "xxUO9RU5pT85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.collections import BrokenBarHCollection\n",
        "\n",
        "def plot_bus_schedules(scheduler):\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "    colors = ['tab:blue', 'tab:orange', 'tab:green']\n",
        "    y_pos = 10  # Start position for the first bus\n",
        "    height = 8  # Height of each bus bar\n",
        "\n",
        "    for i, bus_schedule in enumerate(scheduler.bus_schedules):\n",
        "        bars = []\n",
        "        for departure, destination, arrival in bus_schedule:\n",
        "            bars.append((departure, arrival - departure))\n",
        "\n",
        "        # Add bars for this bus's schedule\n",
        "        ax.add_collection(BrokenBarHCollection(bars, (y_pos, height), facecolors=colors[i]))\n",
        "\n",
        "        # Label the bus\n",
        "        ax.text(-5, y_pos + height / 2, f'Bus {i + 1}', va='center', ha='right', fontsize=12)\n",
        "        y_pos += height + 5  # Move to the next bus\n",
        "\n",
        "    ax.set_ylim(5, y_pos)\n",
        "    ax.set_xlim(0, max([max([arrival for _, _, arrival in schedule]) for schedule in scheduler.bus_schedules]) + 10)\n",
        "    ax.set_xlabel('Time')\n",
        "    ax.set_ylabel('Bus ID')\n",
        "    ax.set_title('Bus Schedules Timeline')\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "\n",
        "plot_bus_schedules(scheduler)\n"
      ],
      "metadata": {
        "id": "MdrVyzdYpXhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_detailed_bus_schedules(scheduler):\n",
        "    fig, ax = plt.subplots(figsize=(14, 8))\n",
        "\n",
        "    colors = ['tab:blue', 'tab:orange', 'tab:green']\n",
        "    y_pos = 0  # Start position for the first bus\n",
        "    bar_height = 0.4  # Height of each bar\n",
        "    trip_height = 1.5  # Vertical space between trips\n",
        "\n",
        "    for bus_id, bus_schedule in enumerate(scheduler.bus_schedules):\n",
        "        for trip_id, (departure, destination, arrival) in enumerate(bus_schedule):\n",
        "            start_station = scheduler.bus_coordinates[bus_id]\n",
        "            end_station = scheduler.bus_coordinates[destination - 1]\n",
        "            distance = scheduler.euclidean_distance(start_station, end_station).item()\n",
        "            travel_time = arrival - departure\n",
        "\n",
        "            # Plot the bar for this trip\n",
        "            ax.barh(y_pos, travel_time, left=departure, height=bar_height, color=colors[bus_id], edgecolor='black')\n",
        "\n",
        "            # Add text annotations for destination, travel time, and distance\n",
        "            ax.text(departure + travel_time / 2, y_pos, f'Station {bus_id + 1} ➔ {destination}',\n",
        "                    va='center', ha='center', color='black', fontsize=10, weight='bold')\n",
        "            ax.text(departure + travel_time + 1, y_pos, f'Time: {travel_time:.2f} s\\nDist: {distance:.2f} units',\n",
        "                    va='center', ha='left', fontsize=9, color='black')\n",
        "\n",
        "            y_pos += trip_height  # Move down for the next trip\n",
        "\n",
        "    ax.set_ylim(-1, y_pos + 1)\n",
        "    ax.set_xlim(0, max([arrival for schedule in scheduler.bus_schedules for _, _, arrival in schedule]) + 10)\n",
        "    ax.set_xlabel('Time (s)')\n",
        "    ax.set_ylabel('Trips')\n",
        "    ax.set_title('Detailed Bus Schedules: Departure Station, Destination, Travel Time, and Distance')\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "plot_detailed_bus_schedules(scheduler)\n"
      ],
      "metadata": {
        "id": "5eBNk5GWqB7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_enhanced_bus_schedule_timeline(scheduler):\n",
        "    fig, ax = plt.subplots(figsize=(16, 9))\n",
        "\n",
        "    color_map = plt.cm.get_cmap('Set2', len(scheduler.bus_schedules))\n",
        "\n",
        "    # Plot each bus's schedule with enhanced design\n",
        "    for bus_id, bus_schedule in enumerate(scheduler.bus_schedules):\n",
        "        for trip_id, (departure, destination, arrival) in enumerate(bus_schedule):\n",
        "            y = bus_id + 1\n",
        "\n",
        "            # Plot the timeline as a bold line with circular markers at each end\n",
        "            ax.plot([departure, arrival], [y, y], color=color_map(bus_id), lw=10, solid_capstyle='round')\n",
        "\n",
        "            # Mark the departure and arrival with circular markers\n",
        "            ax.plot(departure, y, 'o', color='white', markersize=12, markeredgecolor=color_map(bus_id), markeredgewidth=3)\n",
        "            ax.plot(arrival, y, 'o', color='white', markersize=12, markeredgecolor=color_map(bus_id), markeredgewidth=3)\n",
        "\n",
        "            # Add text for the station and destination\n",
        "            ax.text(departure, y + 0.15, f'Station {bus_id + 1}', va='bottom', ha='right', fontsize=12, weight='bold', color='black')\n",
        "            ax.text(arrival, y - 0.15, f'Station {destination}', va='top', ha='left', fontsize=12, weight='bold', color='black')\n",
        "\n",
        "    # Customize the plot's appearance\n",
        "    ax.set_yticks(range(1, len(scheduler.bus_schedules) + 1))\n",
        "    ax.set_yticklabels([f'Bus {i+1}' for i in range(len(scheduler.bus_schedules))], fontsize=14, weight='bold')\n",
        "    ax.set_xlabel('Time (s)', fontsize=16, weight='bold')\n",
        "    ax.set_title('Enhanced Bus Schedule Timeline', fontsize=20, weight='bold', color='darkblue')\n",
        "\n",
        "    # Remove unnecessary spines and add a grid for better clarity\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.spines['left'].set_visible(False)\n",
        "    ax.spines['bottom'].set_linewidth(1.5)\n",
        "    ax.xaxis.grid(True, linestyle='--', linewidth=0.7, color='gray')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "plot_enhanced_bus_schedule_timeline(scheduler)\n"
      ],
      "metadata": {
        "id": "T2vm25lwr237"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import matplotlib.patches as patches\n",
        "import datetime\n",
        "\n",
        "def visualize_bus_schedule_timeline(bus_schedules, bus_coordinates):\n",
        "    fig, ax = plt.subplots(figsize=(15, 8))\n",
        "\n",
        "    # Define colors for the bus lines and stations\n",
        "    bus_colors = ['#FF5733', '#33FF57', '#3357FF']\n",
        "    station_colors = ['#FFD700', '#ADFF2F', '#FF69B4']\n",
        "\n",
        "    # Set the date format on the x-axis\n",
        "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
        "    ax.xaxis.set_major_locator(mdates.MinuteLocator(interval=10))\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "    for i, bus_schedule in enumerate(bus_schedules):\n",
        "        for trip in bus_schedule:\n",
        "            departure_time = datetime.datetime(2024, 8, 9, 0, 0) + datetime.timedelta(seconds=trip[0])\n",
        "            arrival_time = datetime.datetime(2024, 8, 9, 0, 0) + datetime.timedelta(seconds=trip[2])\n",
        "            duration = arrival_time - departure_time\n",
        "\n",
        "            # Plot the timeline\n",
        "            ax.plot([departure_time, arrival_time], [i, i], color=bus_colors[i % len(bus_colors)], lw=4, label=f'Bus {i+1}' if trip == bus_schedule[0] else \"\")\n",
        "\n",
        "            # Add station markers\n",
        "            start_station = trip[1] - 1\n",
        "            ax.scatter(departure_time, i, color=station_colors[start_station], s=200, zorder=5)\n",
        "            ax.scatter(arrival_time, i, color=station_colors[start_station], s=200, zorder=5)\n",
        "\n",
        "            # Annotate the travel time and distance\n",
        "            ax.text(departure_time + duration/2, i + 0.1, f'{int(duration.total_seconds()*60)} min',\n",
        "                    ha='center', va='center', fontsize=12, color='white', bbox=dict(facecolor='black', edgecolor='none', boxstyle='round,pad=0.3'))\n",
        "\n",
        "            ax.text(departure_time + duration/2, i - 0.3, f'Station {start_station + 1} → {trip[1]}',\n",
        "                    ha='center', va='center', fontsize=10, color=bus_colors[i % len(bus_colors)], bbox=dict(facecolor='white', edgecolor='none', boxstyle='round,pad=0.3'))\n",
        "\n",
        "    # Add labels and title\n",
        "    ax.set_yticks(range(len(bus_schedules)))\n",
        "    ax.set_yticklabels([f'Bus {i+1}' for i in range(len(bus_schedules))])\n",
        "    ax.set_xlabel('Time', fontsize=14)\n",
        "    ax.set_title('Bus Schedule Timeline', fontsize=18, fontweight='bold')\n",
        "\n",
        "    # Remove legend duplicates\n",
        "    handles, labels = plt.gca().get_legend_handles_labels()\n",
        "    by_label = dict(zip(labels, handles))\n",
        "    plt.legend(by_label.values(), by_label.keys())\n",
        "\n",
        "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example Usage\n",
        "bus_schedules = scheduler.get_bus_schedules()\n",
        "print(bus_schedules)\n",
        "print(\"\\n \\n \\n \\n\")\n",
        "bus_coordinates = scheduler.get_bus_coordinates()\n",
        "visualize_bus_schedule_timeline(bus_schedules, bus_coordinates)\n"
      ],
      "metadata": {
        "id": "gJCrauU2thMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_points_and_order(scheduler)\n"
      ],
      "metadata": {
        "id": "PzIeOClERs_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_routes_combined(scheduler)"
      ],
      "metadata": {
        "id": "LjWrCKPMRvRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_time_windows(scheduler)"
      ],
      "metadata": {
        "id": "VOplD64kRwvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_drone_and_bus_distance(scheduler)"
      ],
      "metadata": {
        "id": "cqrRCLnGRyTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_time_contribution_pie(scheduler)\n"
      ],
      "metadata": {
        "id": "sTJBBR--T_3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build  The DQN Model"
      ],
      "metadata": {
        "id": "W-7_W_n0OxGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class HybridNetworkEnv:\n",
        "    def __init__(self):\n",
        "        self.drone_speed = 0.045\n",
        "        self.bus_speed = 1.25\n",
        "        self.battery_time = 2  # battery life\n",
        "        self.num_points = 4\n",
        "        self.global_time = 0\n",
        "        self.trip_duration = 80\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Resets the environment to the initial state.\n",
        "\n",
        "        Returns:\n",
        "            A numpy array of size (num_points, 4) containing the coordinates (x, y)\n",
        "            and initial time window (ti, tf) for each point.\n",
        "        \"\"\"\n",
        "        self.global_time = 0\n",
        "        scheduler = TransportationScheduler(self.num_points, self.drone_speed, self.bus_speed, self.trip_duration)  # Create the data\n",
        "\n",
        "        self.bus_coordinates = scheduler.get_bus_coordinates()\n",
        "        self.root= scheduler.coordinates[0].clone()\n",
        "        self.optimal_coordinates = scheduler.calculate_optimal_order(self.root).clone()\n",
        "        self.updated_coordinates = scheduler.calculate_times(self.root).clone()\n",
        "        self.coordinates = scheduler.get_shuffled_coordinates().clone()\n",
        "        self.remaining_deliveries = list(range(1, len(self.coordinates)))  # Delivery indices (excluding depot)\n",
        "        self.bus_schedules = scheduler.generate_bus_schedules()\n",
        "        self.root_location = self.coordinates[0].clone()\n",
        "        self.done = False\n",
        "\n",
        "        print(\"the Optimal order is \\n \",self.updated_coordinates)\n",
        "        print(\"the shuffled point is \\n \",self.coordinates)\n",
        "\n",
        "        return self.root_location, self.remaining_deliveries\n",
        "\n",
        "    def euclidean_distance(self, point1, point2):\n",
        "        return np.linalg.norm(point1[:2] - point2[:2])\n",
        "\n",
        "    def closest_bus_station(self, point):\n",
        "        min_distance = float('inf')\n",
        "        closest_station = None\n",
        "        for i, station in enumerate(self.bus_coordinates):\n",
        "            distance = self.euclidean_distance(point, station)\n",
        "            if distance < min_distance:\n",
        "                min_distance = distance\n",
        "                closest_station = i + 1\n",
        "        return closest_station\n",
        "\n",
        "    def find_next_trip(self, global_time, bus_schedule, start_station, end_station):\n",
        "        for departure, destination, arrival in bus_schedule:\n",
        "            if destination == end_station and departure >= global_time:\n",
        "                waiting_time = departure - global_time\n",
        "                travel_time = arrival - departure\n",
        "                return waiting_time, travel_time\n",
        "        return float('inf'), float('inf')  # If no valid trip is found\n",
        "\n",
        "    def step(self, action):\n",
        "      reward = 0\n",
        "      chosen_point = self.coordinates[action]\n",
        "      # Find the minimum `ti` among all remaining points\n",
        "      min_ti = min([point[2] for point in self.coordinates[self.remaining_deliveries]])\n",
        "      max_tf = max([point[3] for point in self.coordinates[self.remaining_deliveries]])\n",
        "\n",
        "\n",
        "\n",
        "      # Check if the chosen action is valid\n",
        "      if action not in self.remaining_deliveries:\n",
        "          return self.root_location, -1000, self.remaining_deliveries, True\n",
        "\n",
        "      # Calculate the direct travel time to the chosen point using the drone\n",
        "      distance_to_point = self.euclidean_distance(self.root_location, chosen_point)\n",
        "      travel_time_drone = distance_to_point / self.drone_speed\n",
        "\n",
        "      # Check if the drone can directly reach the point without exceeding battery life\n",
        "      if travel_time_drone <= (self.battery_time / 2):\n",
        "          reward = 10\n",
        "          self.global_time += travel_time_drone\n",
        "          self.battery_time -= travel_time_drone\n",
        "          self.remaining_deliveries.remove(action)\n",
        "          self.done = len(self.remaining_deliveries) == 0\n",
        "      else:\n",
        "          # Find the closest bus stations to both the root and the chosen point\n",
        "          closest_station_root = self.closest_bus_station(self.root_location)\n",
        "          closest_station_point = self.closest_bus_station(chosen_point)\n",
        "\n",
        "          # If the root and the chosen point share the same closest bus station, travel directly to the point\n",
        "          if closest_station_root == closest_station_point:\n",
        "              reward = 10\n",
        "              self.global_time += travel_time_drone\n",
        "              self.battery_time -= travel_time_drone\n",
        "              self.remaining_deliveries.remove(action)\n",
        "              self.done = len(self.remaining_deliveries) == 0\n",
        "          else:\n",
        "              # Otherwise, use the bus to travel between stations\n",
        "              distance_root_to_station = self.euclidean_distance(self.root_location, self.bus_coordinates[closest_station_root - 1])\n",
        "              local_time = distance_root_to_station / self.drone_speed\n",
        "\n",
        "              # Find the next bus trip from the closest station to the destination station\n",
        "              waiting_time, travel_time_bus = self.find_next_trip(\n",
        "                  self.global_time,\n",
        "                  self.bus_schedules[closest_station_root - 1],\n",
        "                  closest_station_root,\n",
        "                  closest_station_point\n",
        "              )\n",
        "               # If global_time is less than the minimum `ti`, update global_time to match that value\n",
        "              if self.global_time <= min_ti:\n",
        "                  self.global_time = min_ti\n",
        "                  print(f\"Global time updated to {self.global_time} to match the earliest ti of the remaining points\")\n",
        "              if (self.global_time+local_time) > max_tf:\n",
        "                # If no valid bus trip is found, terminate with a penalty\n",
        "                  self.done = True\n",
        "                  penalty_tensor = torch.tensor(self.root_location, dtype=torch.float32)  # Return the root location as the chosen_point\n",
        "                  return penalty_tensor, -100, self.remaining_deliveries, self.done\n",
        "\n",
        "\n",
        "              if waiting_time != float('inf') and travel_time_bus != float('inf'):\n",
        "                  local_time += waiting_time + travel_time_bus\n",
        "                  distance_point_to_station = self.euclidean_distance(chosen_point, self.bus_coordinates[closest_station_point - 1])\n",
        "                  local_time += (distance_point_to_station / self.drone_speed)+self.global_time\n",
        "\n",
        "\n",
        "                  # Check if the delivery is within the time window\n",
        "                  if local_time >= chosen_point[2] and local_time <= chosen_point[3]:\n",
        "                      reward = 10\n",
        "                      self.global_time += local_time\n",
        "                      self.remaining_deliveries.remove(action)\n",
        "                      self.done = len(self.remaining_deliveries) == 0\n",
        "                  else:\n",
        "\n",
        "                      reward = -10\n",
        "              else:\n",
        "                  # If no valid bus trip is found, terminate with a penalty\n",
        "                  self.done = True\n",
        "                  penalty_tensor = torch.tensor(self.root_location, dtype=torch.float32)  # Return the root location as the chosen_point\n",
        "                  return penalty_tensor, -100, self.remaining_deliveries, self.done\n",
        "\n",
        "      return chosen_point, reward, self.remaining_deliveries, self.done\n",
        "\n",
        "\n",
        "\n",
        "# Example usage\n",
        "env = HybridNetworkEnv()\n",
        "state = env.reset()\n",
        "action = env.remaining_deliveries[2]  # Example action (selecting the third delivery point)\n",
        "next_state, reward, remaining_deliveries, done = env.step(action)\n",
        "print(f\"Next State: {next_state}, Reward: {reward}, Remaining Deliveries: {remaining_deliveries}, Done: {done}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Se08soP4Rf1j",
        "outputId": "54b232a5-975d-42db-9b84-c81e7899811b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the Optimal order is \n",
            "  tensor([[3.5994e-01, 2.1277e-01, 0.0000e+00, 0.0000e+00],\n",
            "        [5.3500e-02, 4.0052e-01, 0.0000e+00, 2.8959e+01],\n",
            "        [3.1319e-01, 8.9782e-01, 3.3074e+01, 6.9212e+01],\n",
            "        [6.5759e-03, 9.7387e-01, 6.6055e+01, 1.0601e+02]])\n",
            "the shuffled point is \n",
            "  tensor([[3.5994e-01, 2.1277e-01, 0.0000e+00, 0.0000e+00],\n",
            "        [5.3500e-02, 4.0052e-01, 0.0000e+00, 2.8959e+01],\n",
            "        [3.1319e-01, 8.9782e-01, 3.3074e+01, 6.9212e+01],\n",
            "        [6.5759e-03, 9.7387e-01, 6.6055e+01, 1.0601e+02]])\n",
            "Global time updated to 0.0 to match the earliest ti of the remaining points\n",
            "Next State: tensor([6.5759e-03, 9.7387e-01, 6.6055e+01, 1.0601e+02]), Reward: -10, Remaining Deliveries: [1, 2, 3], Done: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# TEST THE ENVIRONMENT\n",
        "# Initialize the environment\n",
        "env = HybridNetworkEnv()\n",
        "\n",
        "# Function to run a single episode\n",
        "def run_episode(env, max_steps=8):\n",
        "    state, remaining_deliveries = env.reset()\n",
        "    total_reward = 0\n",
        "\n",
        "    for step in range(max_steps):\n",
        "        # Randomly select an action from the remaining deliveries\n",
        "        if not remaining_deliveries:\n",
        "            break\n",
        "        action = random.choice(remaining_deliveries)\n",
        "\n",
        "        # Take a step in the environment\n",
        "        chosen_point, reward, remaining_deliveries, done = env.step(action)\n",
        "        total_reward += reward\n",
        "\n",
        "        # Print the result of the step\n",
        "        print(f\"Step: {step + 1}\")\n",
        "        print(f\"Action: {action}\")\n",
        "        print(f\"Chosen Point: {chosen_point}\")\n",
        "        print(f\"Reward: {reward}\")\n",
        "        print(f\"Remaining Deliveries: {remaining_deliveries}\")\n",
        "        print(f\"Done: {done}\")\n",
        "        print()\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    print(f\"Total reward: {total_reward}\")\n",
        "\n",
        "# Run a single episode\n",
        "run_episode(env)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcxTzlGAR_6h",
        "outputId": "eccff5d2-fe5b-450b-adca-a9874fc9b161"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the Optimal order is \n",
            "  tensor([[9.1542e-01, 3.3683e-01, 0.0000e+00, 0.0000e+00],\n",
            "        [9.1843e-01, 4.0436e-01, 0.0000e+00, 5.0000e+00],\n",
            "        [5.5957e-01, 4.1969e-02, 5.0000e+00, 4.4001e+01],\n",
            "        [5.5737e-01, 4.9576e-01, 4.3521e+01, 6.8929e+01]])\n",
            "the shuffled point is \n",
            "  tensor([[9.1542e-01, 3.3683e-01, 0.0000e+00, 0.0000e+00],\n",
            "        [5.5737e-01, 4.9576e-01, 4.3521e+01, 6.8929e+01],\n",
            "        [9.1843e-01, 4.0436e-01, 0.0000e+00, 5.0000e+00],\n",
            "        [5.5957e-01, 4.1969e-02, 5.0000e+00, 4.4001e+01]])\n",
            "Step: 1\n",
            "Action: 2\n",
            "Chosen Point: tensor([0.9184, 0.4044, 0.0000, 5.0000])\n",
            "Reward: 10\n",
            "Remaining Deliveries: [1, 3]\n",
            "Done: False\n",
            "\n",
            "Step: 2\n",
            "Action: 3\n",
            "Chosen Point: tensor([5.5957e-01, 4.1969e-02, 5.0000e+00, 4.4001e+01])\n",
            "Reward: 10\n",
            "Remaining Deliveries: [1]\n",
            "Done: False\n",
            "\n",
            "Global time updated to 43.52056121826172 to match the earliest ti of the remaining points\n",
            "Step: 3\n",
            "Action: 1\n",
            "Chosen Point: tensor([ 0.5574,  0.4958, 43.5206, 68.9290])\n",
            "Reward: 10\n",
            "Remaining Deliveries: []\n",
            "Done: True\n",
            "\n",
            "Total reward: 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Agent\n",
        "\n",
        "# Define the neural network\n",
        "class QNetwork(nn.Module):\n",
        "    def __init__(self, state_size, action_size):\n",
        "        super(QNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_size, 64)\n",
        "        self.fc2 = nn.Linear(64, 64)\n",
        "        self.fc3 = nn.Linear(64, action_size)\n",
        "\n",
        "    def forward(self, state):\n",
        "        x = torch.relu(self.fc1(state))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        return self.fc3(x)\n",
        "\n",
        "class DQNAgent:\n",
        "    def __init__(self, state_dim, action_dim, lr=0.001, gamma=0.99, epsilon=1.0, epsilon_decay=0.995, min_epsilon=0.01, memory_size=10000, batch_size=64, target_update=10):\n",
        "        self.state_dim = state_dim\n",
        "        self.action_dim = action_dim\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.min_epsilon = min_epsilon\n",
        "        self.lr = lr\n",
        "        self.batch_size = batch_size\n",
        "        self.memory = deque(maxlen=memory_size)\n",
        "        self.target_update = target_update\n",
        "        self.learn_step_counter = 0\n",
        "\n",
        "        self.q_network = QNetwork(state_dim, action_dim)\n",
        "        self.target_network = QNetwork(state_dim, action_dim)\n",
        "        self.optimizer = optim.Adam(self.q_network.parameters(), lr=self.lr)\n",
        "        self.criterion = nn.MSELoss()\n",
        "\n",
        "        self.update_target_network()\n",
        "\n",
        "    def update_target_network(self):\n",
        "        self.target_network.load_state_dict(self.q_network.state_dict())\n",
        "\n",
        "    def store_transition(self, state, action, reward, next_state, done):\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def get_q_values(self, state):\n",
        "        with torch.no_grad():\n",
        "            q_values = self.q_network(torch.tensor(state, dtype=torch.float32))\n",
        "        return q_values.numpy()\n",
        "    def select_action(self, state, valid_actions):\n",
        "        if random.random() < self.epsilon:\n",
        "            return random.choice(valid_actions)\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                q_values = self.q_network(torch.tensor(state, dtype=torch.float32))\n",
        "                q_values_valid = q_values[valid_actions]\n",
        "                return valid_actions[torch.argmax(q_values_valid).item()]\n",
        "\n",
        "    def experience_replay(self):\n",
        "        if len(self.memory) < self.batch_size:\n",
        "            return\n",
        "\n",
        "        batch = random.sample(self.memory, self.batch_size)\n",
        "        states, actions, rewards, next_states, dones = zip(*batch)\n",
        "\n",
        "        states = torch.tensor(states, dtype=torch.float32)\n",
        "        actions = torch.tensor(actions, dtype=torch.long).unsqueeze(1)\n",
        "        rewards = torch.tensor(rewards, dtype=torch.float32).unsqueeze(1)\n",
        "        next_states = torch.tensor(next_states, dtype=torch.float32)\n",
        "        dones = torch.tensor(dones, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "        q_values = self.q_network(states).gather(1, actions)\n",
        "        next_q_values = self.target_network(next_states).max(1)[0].unsqueeze(1)\n",
        "        target_q_values = rewards + (self.gamma * next_q_values * (1 - dones))\n",
        "\n",
        "        loss = self.criterion(q_values, target_q_values)\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        if self.learn_step_counter % self.target_update == 0:\n",
        "            self.update_target_network()\n",
        "\n",
        "        self.learn_step_counter += 1\n",
        "\n",
        "        if self.epsilon > self.min_epsilon:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "    def train(self, env, episodes):\n",
        "      self.q_values_history = []  # To store states and Q-values\n",
        "      for episode in range(episodes):\n",
        "          state, remaining_deliveries = env.reset()\n",
        "          state = state.numpy()\n",
        "          total_reward = 0\n",
        "          done = False\n",
        "\n",
        "          while not done:\n",
        "              if not remaining_deliveries:\n",
        "                  break  # No valid actions, end episode\n",
        "              action = self.select_action(state, remaining_deliveries)\n",
        "              chosen_point, reward, remaining_deliveries, done= env.step(action)\n",
        "              next_state = chosen_point.numpy()\n",
        "              # Store Q-values for the current state\n",
        "              q_values = self.get_q_values(state)\n",
        "              self.q_values_history.append((state, q_values))\n",
        "\n",
        "              self.store_transition(state, action, reward, next_state, done)\n",
        "              self.experience_replay()\n",
        "\n",
        "              state = next_state\n",
        "              total_reward += reward\n",
        "\n",
        "              # Debugging prints\n",
        "              print(f\"Episode: {episode+1}, Action: {action}, Reward: {reward}, Done: {done}, Valid Actions: {remaining_deliveries}\")\n",
        "\n",
        "          print(f\"Episode {episode+1}: Total Reward: {total_reward}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "M6CSZfScYg_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from collections import deque\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Initialize the environment\n",
        "env = HybridNetworkEnv()\n",
        "\n",
        "# Initialize the agent\n",
        "state_dim = 4  # Adjust according to your state dimension\n",
        "action_dim = env.num_points - 1  # Number of delivery points (excluding the depot)\n",
        "agent = DQNAgent(state_dim, action_dim)\n",
        "\n",
        "# Train the agent\n",
        "agent.train(env, episodes=10)\n",
        "\n",
        "# Visualize Q-values after training\n",
        "def visualize_q_values_from_training(agent):\n",
        "    for i, (state, q_values) in enumerate(agent.q_values_history):\n",
        "        print(f\"State {i+1}: {state}\")\n",
        "        print(f\"Q-values: {q_values}\")\n",
        "        plt.bar(range(len(q_values)), q_values)\n",
        "        plt.xlabel('Actions')\n",
        "        plt.ylabel('Q-values')\n",
        "        plt.title(f'Q-values for State {i+1}')\n",
        "        plt.show()\n",
        "# Function to run a single episode and test the model\n",
        "def run_episode(env, agent, max_steps=5):\n",
        "    state, remaining_deliveries = env.reset()\n",
        "    state = state.numpy()\n",
        "    total_reward = 0\n",
        "    done = False\n",
        "\n",
        "    for step in range(max_steps):\n",
        "        if not remaining_deliveries:\n",
        "            break\n",
        "        action = agent.select_action(state, remaining_deliveries)\n",
        "        chosen_point, reward, remaining_deliveries, done = env.step(action)\n",
        "        next_state = chosen_point.numpy()\n",
        "\n",
        "        state = next_state\n",
        "        total_reward += reward\n",
        "\n",
        "        # Print the result of the step\n",
        "        print(f\"Step: {step + 1}\")\n",
        "        print(f\"Action: {action}\")\n",
        "        print(f\"State: {state}\")\n",
        "        print(f\"Reward: {reward}\")\n",
        "        print(f\"Done: {done}\")\n",
        "        print()\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    print(f\"Total reward: {total_reward}\")\n",
        "\n",
        "# Run a single episode to test the trained model\n",
        "run_episode(env, agent)\n",
        "# visualize_q_values_from_training(agent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba6_B3GdYslP",
        "outputId": "f0670e91-e4a9-4049-ed7e-3c76ff909860"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the Optimal order is \n",
            "  tensor([[  0.8549,   0.4180,   0.0000,   0.0000],\n",
            "        [  0.9686,   0.5187,   0.0000,   5.0000],\n",
            "        [  0.7851,   0.5966,  39.0023,  75.5179],\n",
            "        [  0.5489,   0.9592,  84.6936, 126.0123]])\n",
            "the shuffled point is \n",
            "  tensor([[  0.8549,   0.4180,   0.0000,   0.0000],\n",
            "        [  0.9686,   0.5187,   0.0000,   5.0000],\n",
            "        [  0.7851,   0.5966,  39.0023,  75.5179],\n",
            "        [  0.5489,   0.9592,  84.6936, 126.0123]])\n",
            "Global time updated to 0.0 to match the earliest ti of the remaining points\n",
            "Episode: 1, Action: 2, Reward: -10, Done: False, Valid Actions: [1, 2, 3]\n",
            "Global time updated to 0.0 to match the earliest ti of the remaining points\n",
            "Episode: 1, Action: 2, Reward: -10, Done: False, Valid Actions: [1, 2, 3]\n",
            "Global time updated to 0.0 to match the earliest ti of the remaining points\n",
            "Episode: 1, Action: 3, Reward: -10, Done: False, Valid Actions: [1, 2, 3]\n",
            "Global time updated to 0.0 to match the earliest ti of the remaining points\n",
            "Episode: 1, Action: 3, Reward: -10, Done: False, Valid Actions: [1, 2, 3]\n",
            "Global time updated to 0.0 to match the earliest ti of the remaining points\n",
            "Episode: 1, Action: 2, Reward: -10, Done: False, Valid Actions: [1, 2, 3]\n",
            "Global time updated to 0.0 to match the earliest ti of the remaining points\n",
            "Episode: 1, Action: 2, Reward: -10, Done: False, Valid Actions: [1, 2, 3]\n",
            "Global time updated to 0.0 to match the earliest ti of the remaining points\n",
            "Episode: 1, Action: 2, Reward: -10, Done: False, Valid Actions: [1, 2, 3]\n",
            "Global time updated to 0.0 to match the earliest ti of the remaining points\n",
            "Episode: 1, Action: 2, Reward: -10, Done: False, Valid Actions: [1, 2, 3]\n",
            "Global time updated to 0.0 to match the earliest ti of the remaining points\n",
            "Episode: 1, Action: 3, Reward: -10, Done: False, Valid Actions: [1, 2, 3]\n",
            "Global time updated to 0.0 to match the earliest ti of the remaining points\n",
            "Episode: 1, Action: 2, Reward: -10, Done: False, Valid Actions: [1, 2, 3]\n",
            "Episode: 1, Action: 1, Reward: 10, Done: False, Valid Actions: [2, 3]\n",
            "Global time updated to 39.002315521240234 to match the earliest ti of the remaining points\n",
            "Episode: 1, Action: 3, Reward: -100, Done: True, Valid Actions: [2, 3]\n",
            "Episode 1: Total Reward: -190\n",
            "the Optimal order is \n",
            "  tensor([[3.7501e-01, 5.6544e-01, 0.0000e+00, 0.0000e+00],\n",
            "        [4.4850e-02, 9.0512e-01, 3.3531e+01, 7.7092e+01],\n",
            "        [3.8170e-01, 9.0789e-01, 7.4701e+01, 1.0075e+02],\n",
            "        [5.6109e-01, 4.6756e-02, 1.0128e+02, 1.3348e+02]])\n",
            "the shuffled point is \n",
            "  tensor([[3.7501e-01, 5.6544e-01, 0.0000e+00, 0.0000e+00],\n",
            "        [3.8170e-01, 9.0789e-01, 7.4701e+01, 1.0075e+02],\n",
            "        [5.6109e-01, 4.6756e-02, 1.0128e+02, 1.3348e+02],\n",
            "        [4.4850e-02, 9.0512e-01, 3.3531e+01, 7.7092e+01]])\n",
            "Global time updated to 33.531158447265625 to match the earliest ti of the remaining points\n",
            "Episode: 2, Action: 2, Reward: -10, Done: False, Valid Actions: [1, 2, 3]\n",
            "Global time updated to 33.531158447265625 to match the earliest ti of the remaining points\n",
            "Episode: 2, Action: 1, Reward: -10, Done: False, Valid Actions: [1, 2, 3]\n",
            "Global time updated to 33.531158447265625 to match the earliest ti of the remaining points\n",
            "Episode: 2, Action: 1, Reward: -10, Done: False, Valid Actions: [1, 2, 3]\n",
            "Global time updated to 33.531158447265625 to match the earliest ti of the remaining points\n",
            "Episode: 2, Action: 2, Reward: -100, Done: True, Valid Actions: [1, 2, 3]\n",
            "Episode 2: Total Reward: -130\n",
            "the Optimal order is \n",
            "  tensor([[ 0.7076,  0.5520,  0.0000,  0.0000],\n",
            "        [ 0.3416,  0.1328,  0.0000, 58.8704],\n",
            "        [ 0.9217,  0.6953, 40.9136, 45.9136],\n",
            "        [ 0.9461,  0.7098, 45.9136, 52.8074]])\n",
            "the shuffled point is \n",
            "  tensor([[ 0.7076,  0.5520,  0.0000,  0.0000],\n",
            "        [ 0.3416,  0.1328,  0.0000, 58.8704],\n",
            "        [ 0.9217,  0.6953, 40.9136, 45.9136],\n",
            "        [ 0.9461,  0.7098, 45.9136, 52.8074]])\n",
            "Episode: 3, Action: 1, Reward: 10, Done: False, Valid Actions: [2, 3]\n",
            "Episode: 3, Action: 3, Reward: 10, Done: False, Valid Actions: [2]\n",
            "Episode: 3, Action: 2, Reward: 10, Done: True, Valid Actions: []\n",
            "Episode 3: Total Reward: 30\n",
            "the Optimal order is \n",
            "  tensor([[3.8931e-01, 4.2266e-01, 0.0000e+00, 0.0000e+00],\n",
            "        [5.0258e-01, 2.8210e-01, 0.0000e+00, 5.0000e+00],\n",
            "        [1.7044e-02, 1.7910e-01, 5.0000e+00, 4.3089e+01],\n",
            "        [9.2018e-01, 7.4648e-02, 7.5238e+01, 1.2623e+02]])\n",
            "the shuffled point is \n",
            "  tensor([[3.8931e-01, 4.2266e-01, 0.0000e+00, 0.0000e+00],\n",
            "        [1.7044e-02, 1.7910e-01, 5.0000e+00, 4.3089e+01],\n",
            "        [9.2018e-01, 7.4648e-02, 7.5238e+01, 1.2623e+02],\n",
            "        [5.0258e-01, 2.8210e-01, 0.0000e+00, 5.0000e+00]])\n",
            "Global time updated to 0.0 to match the earliest ti of the remaining points\n",
            "Episode: 4, Action: 2, Reward: -10, Done: False, Valid Actions: [1, 2, 3]\n",
            "Global time updated to 0.0 to match the earliest ti of the remaining points\n",
            "Episode: 4, Action: 2, Reward: -10, Done: False, Valid Actions: [1, 2, 3]\n",
            "Episode: 4, Action: 3, Reward: 10, Done: False, Valid Actions: [1, 2]\n",
            "Episode: 4, Action: 1, Reward: 10, Done: False, Valid Actions: [2]\n",
            "Global time updated to 75.23844909667969 to match the earliest ti of the remaining points\n",
            "Episode: 4, Action: 2, Reward: 10, Done: True, Valid Actions: []\n",
            "Episode 4: Total Reward: 10\n",
            "the Optimal order is \n",
            "  tensor([[  0.5821,   0.5897,   0.0000,   0.0000],\n",
            "        [  0.2780,   0.1362,   0.0000,  64.5761],\n",
            "        [  0.9096,   0.7683,  44.7174,  49.7174],\n",
            "        [  0.9690,   0.3817,  65.5999, 100.9640]])\n",
            "the shuffled point is \n",
            "  tensor([[  0.5821,   0.5897,   0.0000,   0.0000],\n",
            "        [  0.2780,   0.1362,   0.0000,  64.5761],\n",
            "        [  0.9690,   0.3817,  65.5999, 100.9640],\n",
            "        [  0.9096,   0.7683,  44.7174,  49.7174]])\n",
            "Episode: 5, Action: 3, Reward: 10, Done: False, Valid Actions: [1, 2]\n",
            "Episode: 5, Action: 2, Reward: -10, Done: False, Valid Actions: [1, 2]\n",
            "Episode: 5, Action: 2, Reward: -10, Done: False, Valid Actions: [1, 2]\n",
            "Episode: 5, Action: 1, Reward: 10, Done: False, Valid Actions: [2]\n",
            "Global time updated to 65.5998764038086 to match the earliest ti of the remaining points\n",
            "Episode: 5, Action: 2, Reward: -10, Done: False, Valid Actions: [2]\n",
            "Global time updated to 65.5998764038086 to match the earliest ti of the remaining points\n",
            "Episode: 5, Action: 2, Reward: -100, Done: True, Valid Actions: [2]\n",
            "Episode 5: Total Reward: -110\n",
            "the Optimal order is \n",
            "  tensor([[7.0631e-01, 3.8215e-02, 0.0000e+00, 0.0000e+00],\n",
            "        [6.7285e-01, 2.0953e-02, 0.0000e+00, 7.5104e+00],\n",
            "        [8.7296e-01, 6.9828e-01, 7.4442e+01, 1.6268e+02],\n",
            "        [8.3393e-01, 7.6997e-01, 1.5660e+02, 1.9669e+02]])\n",
            "the shuffled point is \n",
            "  tensor([[7.0631e-01, 3.8215e-02, 0.0000e+00, 0.0000e+00],\n",
            "        [8.3393e-01, 7.6997e-01, 1.5660e+02, 1.9669e+02],\n",
            "        [8.7296e-01, 6.9828e-01, 7.4442e+01, 1.6268e+02],\n",
            "        [6.7285e-01, 2.0953e-02, 0.0000e+00, 7.5104e+00]])\n",
            "Global time updated to 0.0 to match the earliest ti of the remaining points\n",
            "Episode: 6, Action: 2, Reward: -100, Done: True, Valid Actions: [1, 2, 3]\n",
            "Episode 6: Total Reward: -100\n",
            "the Optimal order is \n",
            "  tensor([[1.9287e-01, 2.0342e-01, 0.0000e+00, 0.0000e+00],\n",
            "        [1.8805e-01, 1.6444e-01, 0.0000e+00, 1.8037e+01],\n",
            "        [5.7646e-03, 2.3525e-01, 1.3691e+01, 1.8691e+01],\n",
            "        [8.6203e-01, 4.1823e-01, 3.6151e+01, 8.4035e+01]])\n",
            "the shuffled point is \n",
            "  tensor([[1.9287e-01, 2.0342e-01, 0.0000e+00, 0.0000e+00],\n",
            "        [5.7646e-03, 2.3525e-01, 1.3691e+01, 1.8691e+01],\n",
            "        [8.6203e-01, 4.1823e-01, 3.6151e+01, 8.4035e+01],\n",
            "        [1.8805e-01, 1.6444e-01, 0.0000e+00, 1.8037e+01]])\n",
            "Global time updated to 0.0 to match the earliest ti of the remaining points\n",
            "Episode: 7, Action: 2, Reward: -10, Done: False, Valid Actions: [1, 2, 3]\n",
            "Episode: 7, Action: 1, Reward: 10, Done: False, Valid Actions: [2, 3]\n",
            "Episode: 7, Action: 2, Reward: -10, Done: False, Valid Actions: [2, 3]\n",
            "Episode: 7, Action: 2, Reward: -10, Done: False, Valid Actions: [2, 3]\n",
            "Episode: 7, Action: 2, Reward: -10, Done: False, Valid Actions: [2, 3]\n",
            "Episode: 7, Action: 3, Reward: 10, Done: False, Valid Actions: [2]\n",
            "Global time updated to 36.150936126708984 to match the earliest ti of the remaining points\n",
            "Episode: 7, Action: 2, Reward: 10, Done: True, Valid Actions: []\n",
            "Episode 7: Total Reward: -10\n",
            "the Optimal order is \n",
            "  tensor([[7.6701e-01, 8.2841e-01, 0.0000e+00, 0.0000e+00],\n",
            "        [2.6592e-01, 1.2695e-01, 0.0000e+00, 1.0638e+01],\n",
            "        [3.2310e-01, 6.4627e-02, 8.7590e+00, 1.3759e+01],\n",
            "        [9.2861e-01, 1.3514e-01, 6.0839e+01, 1.1280e+02]])\n",
            "the shuffled point is \n",
            "  tensor([[7.6701e-01, 8.2841e-01, 0.0000e+00, 0.0000e+00],\n",
            "        [9.2861e-01, 1.3514e-01, 6.0839e+01, 1.1280e+02],\n",
            "        [3.2310e-01, 6.4627e-02, 8.7590e+00, 1.3759e+01],\n",
            "        [2.6592e-01, 1.2695e-01, 0.0000e+00, 1.0638e+01]])\n",
            "Episode: 8, Action: 2, Reward: 10, Done: False, Valid Actions: [1, 3]\n",
            "Episode: 8, Action: 1, Reward: -10, Done: False, Valid Actions: [1, 3]\n",
            "Episode: 8, Action: 3, Reward: 10, Done: False, Valid Actions: [1]\n",
            "Global time updated to 60.83911895751953 to match the earliest ti of the remaining points\n",
            "Episode: 8, Action: 1, Reward: 10, Done: True, Valid Actions: []\n",
            "Episode 8: Total Reward: 20\n",
            "the Optimal order is \n",
            "  tensor([[6.8669e-02, 4.2375e-01, 0.0000e+00, 0.0000e+00],\n",
            "        [3.5623e-01, 6.7355e-01, 1.4643e+01, 4.7759e+01],\n",
            "        [1.4088e-01, 2.9302e-01, 5.3937e+01, 8.6111e+01],\n",
            "        [7.2923e-01, 9.8581e-02, 9.7435e+01, 1.3636e+02]])\n",
            "the shuffled point is \n",
            "  tensor([[6.8669e-02, 4.2375e-01, 0.0000e+00, 0.0000e+00],\n",
            "        [1.4088e-01, 2.9302e-01, 5.3937e+01, 8.6111e+01],\n",
            "        [3.5623e-01, 6.7355e-01, 1.4643e+01, 4.7759e+01],\n",
            "        [7.2923e-01, 9.8581e-02, 9.7435e+01, 1.3636e+02]])\n",
            "Global time updated to 14.643058776855469 to match the earliest ti of the remaining points\n",
            "Episode: 9, Action: 1, Reward: -10, Done: False, Valid Actions: [1, 2, 3]\n",
            "Global time updated to 14.643058776855469 to match the earliest ti of the remaining points\n",
            "Episode: 9, Action: 1, Reward: -10, Done: False, Valid Actions: [1, 2, 3]\n",
            "Global time updated to 14.643058776855469 to match the earliest ti of the remaining points\n",
            "Episode: 9, Action: 2, Reward: 10, Done: False, Valid Actions: [1, 3]\n",
            "Global time updated to 53.93743133544922 to match the earliest ti of the remaining points\n",
            "Episode: 9, Action: 1, Reward: 10, Done: False, Valid Actions: [3]\n",
            "Episode: 9, Action: 3, Reward: -100, Done: True, Valid Actions: [3]\n",
            "Episode 9: Total Reward: -100\n",
            "the Optimal order is \n",
            "  tensor([[7.4503e-01, 2.7036e-02, 0.0000e+00, 0.0000e+00],\n",
            "        [7.4612e-01, 5.7284e-01, 3.3989e+01, 8.2218e+01],\n",
            "        [2.5117e-01, 3.5689e-01, 7.8681e+01, 1.1185e+02],\n",
            "        [5.0149e-01, 9.7498e-01, 1.0725e+02, 1.5088e+02]])\n",
            "the shuffled point is \n",
            "  tensor([[7.4503e-01, 2.7036e-02, 0.0000e+00, 0.0000e+00],\n",
            "        [5.0149e-01, 9.7498e-01, 1.0725e+02, 1.5088e+02],\n",
            "        [2.5117e-01, 3.5689e-01, 7.8681e+01, 1.1185e+02],\n",
            "        [7.4612e-01, 5.7284e-01, 3.3989e+01, 8.2218e+01]])\n",
            "Global time updated to 33.98873519897461 to match the earliest ti of the remaining points\n",
            "Episode: 10, Action: 2, Reward: -10, Done: False, Valid Actions: [1, 2, 3]\n",
            "Global time updated to 33.98873519897461 to match the earliest ti of the remaining points\n",
            "Episode: 10, Action: 1, Reward: -100, Done: True, Valid Actions: [1, 2, 3]\n",
            "Episode 10: Total Reward: -110\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-32550230feeb>:137: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  penalty_tensor = torch.tensor(self.root_location, dtype=torch.float32)  # Return the root location as the chosen_point\n",
            "<ipython-input-6-32550230feeb>:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  penalty_tensor = torch.tensor(self.root_location, dtype=torch.float32)  # Return the root location as the chosen_point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the Optimal order is \n",
            "  tensor([[9.1744e-01, 2.9183e-01, 0.0000e+00, 0.0000e+00],\n",
            "        [6.3433e-01, 1.6248e-01, 0.0000e+00, 5.0000e+00],\n",
            "        [3.1826e-01, 2.4304e-01, 3.5197e+01, 7.4835e+01],\n",
            "        [2.2626e-02, 7.8086e-01, 7.7387e+01, 1.1474e+02]])\n",
            "the shuffled point is \n",
            "  tensor([[9.1744e-01, 2.9183e-01, 0.0000e+00, 0.0000e+00],\n",
            "        [6.3433e-01, 1.6248e-01, 0.0000e+00, 5.0000e+00],\n",
            "        [3.1826e-01, 2.4304e-01, 3.5197e+01, 7.4835e+01],\n",
            "        [2.2626e-02, 7.8086e-01, 7.7387e+01, 1.1474e+02]])\n",
            "Global time updated to 0.0 to match the earliest ti of the remaining points\n",
            "Step: 1\n",
            "Action: 2\n",
            "State: [ 0.31825697  0.24303532 35.196556   74.835266  ]\n",
            "Reward: -10\n",
            "Done: False\n",
            "\n",
            "Step: 2\n",
            "Action: 1\n",
            "State: [0.6343348  0.16247523 0.         5.        ]\n",
            "Reward: 10\n",
            "Done: False\n",
            "\n",
            "Global time updated to 35.196556091308594 to match the earliest ti of the remaining points\n",
            "Step: 3\n",
            "Action: 3\n",
            "State: [2.2626221e-02 7.8086245e-01 7.7387329e+01 1.1473790e+02]\n",
            "Reward: -10\n",
            "Done: False\n",
            "\n",
            "Global time updated to 35.196556091308594 to match the earliest ti of the remaining points\n",
            "Step: 4\n",
            "Action: 3\n",
            "State: [2.2626221e-02 7.8086245e-01 7.7387329e+01 1.1473790e+02]\n",
            "Reward: -10\n",
            "Done: False\n",
            "\n",
            "Global time updated to 35.196556091308594 to match the earliest ti of the remaining points\n",
            "Step: 5\n",
            "Action: 3\n",
            "State: [2.2626221e-02 7.8086245e-01 7.7387329e+01 1.1473790e+02]\n",
            "Reward: -10\n",
            "Done: False\n",
            "\n",
            "Total reward: -30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Evaluate the Model"
      ],
      "metadata": {
        "id": "jzK3Uky6ozMW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1. Run Multiple Test Episodes"
      ],
      "metadata": {
        "id": "euNVx_9To2fx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_agent(env, agent, num_episodes=10):\n",
        "    rewards = []\n",
        "    for episode in range(num_episodes):\n",
        "        state = env.reset()\n",
        "        done = False\n",
        "        total_reward = 0\n",
        "\n",
        "        while not done:\n",
        "            # Get the valid actions for the current state\n",
        "            valid_actions = env.remaining_deliveries\n",
        "\n",
        "            # Select an action using the agent, ensuring exploration is disabled\n",
        "            action = agent.select_action(state, valid_actions)\n",
        "\n",
        "            # Take the action in the environment\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "\n",
        "            # Update the total reward and move to the next state\n",
        "            total_reward += reward\n",
        "            state = next_state\n",
        "\n",
        "        # Store the total reward for this episode\n",
        "        rewards.append(total_reward)\n",
        "\n",
        "    return rewards\n",
        "\n"
      ],
      "metadata": {
        "id": "mZzsiUujovx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2. Analyze the Results"
      ],
      "metadata": {
        "id": "BTmhhRMGo9NZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_results(rewards):\n",
        "    print(f\"Average Reward: {sum(rewards)/len(rewards)}\")\n",
        "    print(f\"Max Reward: {max(rewards)}\")\n",
        "    print(f\"Min Reward: {min(rewards)}\")"
      ],
      "metadata": {
        "id": "FAkRDgWIo8tK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3. Visualize the Results"
      ],
      "metadata": {
        "id": "ULGu-2VspEXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_rewards(rewards):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(rewards, label=\"Episode Reward\")\n",
        "    plt.xlabel(\"Episode\")\n",
        "    plt.ylabel(\"Total Reward\")\n",
        "    plt.title(\"Agent Performance Over Time\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "rewards = evaluate_agent(env, agent)\n",
        "analyze_results(rewards)\n",
        "visualize_rewards(rewards)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-cv0XnMNpGyF",
        "outputId": "815848ea-e86f-47fd-b7ce-bbb5cf81cb17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the Optimal order is \n",
            "  tensor([[  0.8722,   0.3384,   0.0000,   0.0000],\n",
            "        [  0.5798,   0.4863,  54.6110, 114.0880],\n",
            "        [  0.3476,   0.4091, 116.0217, 145.9427],\n",
            "        [  0.3001,   0.8680, 143.3951, 178.2947]])\n",
            "the shuffled point is \n",
            "  tensor([[  0.8722,   0.3384,   0.0000,   0.0000],\n",
            "        [  0.3476,   0.4091, 116.0217, 145.9427],\n",
            "        [  0.3001,   0.8680, 143.3951, 178.2947],\n",
            "        [  0.5798,   0.4863,  54.6110, 114.0880]])\n",
            "Global time updated to 54.61102294921875 to match the earliest ti of the remaining points\n",
            "the Optimal order is \n",
            "  tensor([[2.5395e-01, 3.6864e-01, 0.0000e+00, 0.0000e+00],\n",
            "        [8.0979e-01, 7.3769e-01, 0.0000e+00, 6.2614e+01],\n",
            "        [6.0062e-01, 9.1285e-01, 4.3409e+01, 1.0118e+02],\n",
            "        [3.0869e-02, 3.6334e-01, 8.3590e+01, 8.8590e+01]])\n",
            "the shuffled point is \n",
            "  tensor([[2.5395e-01, 3.6864e-01, 0.0000e+00, 0.0000e+00],\n",
            "        [6.0062e-01, 9.1285e-01, 4.3409e+01, 1.0118e+02],\n",
            "        [8.0979e-01, 7.3769e-01, 0.0000e+00, 6.2614e+01],\n",
            "        [3.0869e-02, 3.6334e-01, 8.3590e+01, 8.8590e+01]])\n",
            "the Optimal order is \n",
            "  tensor([[1.1306e-01, 3.5143e-01, 0.0000e+00, 0.0000e+00],\n",
            "        [8.8520e-01, 3.2846e-03, 3.9607e+01, 9.2178e+01],\n",
            "        [9.5810e-01, 2.2584e-02, 8.7566e+01, 1.3064e+02],\n",
            "        [4.1294e-01, 8.2586e-01, 1.2470e+02, 1.6225e+02]])\n",
            "the shuffled point is \n",
            "  tensor([[1.1306e-01, 3.5143e-01, 0.0000e+00, 0.0000e+00],\n",
            "        [9.5810e-01, 2.2584e-02, 8.7566e+01, 1.3064e+02],\n",
            "        [8.8520e-01, 3.2846e-03, 3.9607e+01, 9.2178e+01],\n",
            "        [4.1294e-01, 8.2586e-01, 1.2470e+02, 1.6225e+02]])\n",
            "Global time updated to 39.60679626464844 to match the earliest ti of the remaining points\n",
            "the Optimal order is \n",
            "  tensor([[7.7574e-01, 1.5391e-01, 0.0000e+00, 0.0000e+00],\n",
            "        [9.1581e-01, 5.0425e-01, 0.0000e+00, 5.0000e+00],\n",
            "        [7.0759e-01, 9.4374e-01, 5.8403e+01, 1.2549e+02],\n",
            "        [1.6625e-01, 9.7963e-01, 1.2769e+02, 1.6833e+02]])\n",
            "the shuffled point is \n",
            "  tensor([[7.7574e-01, 1.5391e-01, 0.0000e+00, 0.0000e+00],\n",
            "        [7.0759e-01, 9.4374e-01, 5.8403e+01, 1.2549e+02],\n",
            "        [1.6625e-01, 9.7963e-01, 1.2769e+02, 1.6833e+02],\n",
            "        [9.1581e-01, 5.0425e-01, 0.0000e+00, 5.0000e+00]])\n",
            "Global time updated to 0.0 to match the earliest ti of the remaining points\n",
            "the Optimal order is \n",
            "  tensor([[7.0347e-01, 4.3435e-01, 0.0000e+00, 0.0000e+00],\n",
            "        [8.6011e-01, 5.9672e-01, 0.0000e+00, 5.9579e+01],\n",
            "        [6.3267e-02, 4.0887e-01, 4.1386e+01, 4.6386e+01],\n",
            "        [1.3240e-02, 5.0794e-01, 6.1300e+01, 9.1867e+01]])\n",
            "the shuffled point is \n",
            "  tensor([[7.0347e-01, 4.3435e-01, 0.0000e+00, 0.0000e+00],\n",
            "        [1.3240e-02, 5.0794e-01, 6.1300e+01, 9.1867e+01],\n",
            "        [8.6011e-01, 5.9672e-01, 0.0000e+00, 5.9579e+01],\n",
            "        [6.3267e-02, 4.0887e-01, 4.1386e+01, 4.6386e+01]])\n",
            "Global time updated to 0.0 to match the earliest ti of the remaining points\n",
            "the Optimal order is \n",
            "  tensor([[6.4077e-01, 1.7818e-01, 0.0000e+00, 0.0000e+00],\n",
            "        [6.7194e-01, 4.5964e-01, 5.5088e+01, 1.1570e+02],\n",
            "        [7.2870e-01, 5.7066e-01, 1.1910e+02, 1.4805e+02],\n",
            "        [1.0026e-01, 9.6234e-01, 1.4880e+02, 1.8739e+02]])\n",
            "the shuffled point is \n",
            "  tensor([[6.4077e-01, 1.7818e-01, 0.0000e+00, 0.0000e+00],\n",
            "        [6.7194e-01, 4.5964e-01, 5.5088e+01, 1.1570e+02],\n",
            "        [1.0026e-01, 9.6234e-01, 1.4880e+02, 1.8739e+02],\n",
            "        [7.2870e-01, 5.7066e-01, 1.1910e+02, 1.4805e+02]])\n",
            "Global time updated to 55.08757781982422 to match the earliest ti of the remaining points\n",
            "the Optimal order is \n",
            "  tensor([[4.2344e-01, 4.7975e-01, 0.0000e+00, 0.0000e+00],\n",
            "        [3.3262e-01, 3.5937e-01, 0.0000e+00, 4.3812e+01],\n",
            "        [8.6739e-01, 5.8947e-01, 3.0874e+01, 3.5874e+01],\n",
            "        [1.0587e-01, 8.3439e-01, 7.8799e+01, 1.3214e+02]])\n",
            "the shuffled point is \n",
            "  tensor([[4.2344e-01, 4.7975e-01, 0.0000e+00, 0.0000e+00],\n",
            "        [1.0587e-01, 8.3439e-01, 7.8799e+01, 1.3214e+02],\n",
            "        [8.6739e-01, 5.8947e-01, 3.0874e+01, 3.5874e+01],\n",
            "        [3.3262e-01, 3.5937e-01, 0.0000e+00, 4.3812e+01]])\n",
            "the Optimal order is \n",
            "  tensor([[6.5771e-02, 3.3602e-01, 0.0000e+00, 0.0000e+00],\n",
            "        [4.8869e-02, 2.0823e-01, 0.0000e+00, 5.0000e+00],\n",
            "        [2.5815e-01, 1.0025e-02, 5.0000e+00, 2.9216e+01],\n",
            "        [7.7042e-01, 2.1278e-01, 6.2335e+01, 1.0821e+02]])\n",
            "the shuffled point is \n",
            "  tensor([[6.5771e-02, 3.3602e-01, 0.0000e+00, 0.0000e+00],\n",
            "        [7.7042e-01, 2.1278e-01, 6.2335e+01, 1.0821e+02],\n",
            "        [4.8869e-02, 2.0823e-01, 0.0000e+00, 5.0000e+00],\n",
            "        [2.5815e-01, 1.0025e-02, 5.0000e+00, 2.9216e+01]])\n",
            "the Optimal order is \n",
            "  tensor([[ 0.5133,  0.6050,  0.0000,  0.0000],\n",
            "        [ 0.7231,  0.5055,  0.0000, 30.9895],\n",
            "        [ 0.7610,  0.4315, 22.3263, 58.7783],\n",
            "        [ 0.4852,  0.8143, 48.2943, 53.2943]])\n",
            "the shuffled point is \n",
            "  tensor([[ 0.5133,  0.6050,  0.0000,  0.0000],\n",
            "        [ 0.4852,  0.8143, 48.2943, 53.2943],\n",
            "        [ 0.7610,  0.4315, 22.3263, 58.7783],\n",
            "        [ 0.7231,  0.5055,  0.0000, 30.9895]])\n",
            "the Optimal order is \n",
            "  tensor([[  0.8129,   0.3546,   0.0000,   0.0000],\n",
            "        [  0.4742,   0.3635,  35.0155,  76.0289],\n",
            "        [  0.7421,   0.4205,  78.1182, 100.5513],\n",
            "        [  0.7266,   0.6668, 108.0199, 136.0914]])\n",
            "the shuffled point is \n",
            "  tensor([[  0.8129,   0.3546,   0.0000,   0.0000],\n",
            "        [  0.4742,   0.3635,  35.0155,  76.0289],\n",
            "        [  0.7421,   0.4205,  78.1182, 100.5513],\n",
            "        [  0.7266,   0.6668, 108.0199, 136.0914]])\n",
            "Global time updated to 35.015541076660156 to match the earliest ti of the remaining points\n",
            "Average Reward: 0.0\n",
            "Max Reward: 10\n",
            "Min Reward: -10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Refine the Model\n"
      ],
      "metadata": {
        "id": "iSapesrrpj_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to train and evaluate the agent\n",
        "def train_and_evaluate(agent, env, episodes=1):\n",
        "    agent.train(env, episodes=episodes)\n",
        "    rewards = evaluate_agent(env, agent)\n",
        "    return rewards\n",
        "\n",
        "# Define hyperparameters to experiment with\n",
        "learning_rates = [0.001, 0.0001 ] #0.001, 0.0001, 0.00001\n",
        "gammas = [0.99, 0.95] #0.99, 0.95, 0.90\n",
        "epsilon_decays = [0.995, 0.99]#0.995, 0.99, 0.98\n",
        "\n",
        "# Dictionary to store results\n",
        "results = {}\n",
        "\n",
        "for lr in learning_rates:\n",
        "    for gamma in gammas:\n",
        "        for epsilon_decay in epsilon_decays:\n",
        "            print(f\"Training with lr={lr}, gamma={gamma}, epsilon_decay={epsilon_decay}\")\n",
        "            # Initialize the environment\n",
        "            env = HybridNetworkEnv()\n",
        "\n",
        "            # Initialize the agent\n",
        "            state_dim = 4  # Adjust according to your state dimension\n",
        "            action_dim = env.num_points - 1  # Number of delivery points (excluding the depot)\n",
        "            agent = DQNAgent(\n",
        "                state_dim,\n",
        "                action_dim=action_dim,\n",
        "                lr=lr,\n",
        "                gamma=gamma,\n",
        "            )\n",
        "            rewards = train_and_evaluate(agent, env)\n",
        "            results[(lr, gamma, epsilon_decay)] = rewards\n",
        "\n",
        "# Function to visualize results\n",
        "def visualize_results(results):\n",
        "    for (lr, gamma, epsilon_decay), rewards in results.items():\n",
        "        plt.plot(rewards, label=f'LR: {lr}, Gamma: {gamma}, Decay: {epsilon_decay}')\n",
        "\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Total Reward')\n",
        "    plt.title('Training Rewards for Different Hyperparameters')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize the results\n",
        "visualize_results(results)\n",
        "\n"
      ],
      "metadata": {
        "id": "m_qJnJZSpslp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}